{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/mayankmaheshwari/Desktop/oodles/\")\n",
    "import uuid\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import entropy\n",
    "from oodles import Framework, monitor, Anomaly, DataDriftAlgo, AbstractAnomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   uuid  feature1  feature2  feature3  \\\n",
      "0  826155b3-216b-441f-83ca-2bd9023d28ca  0.562116  0.056333  0.570388   \n",
      "1  3d78e8b4-5993-41a5-8cb9-ae8a2fa67160  0.751102  0.659187  0.022919   \n",
      "2  7bb77e13-4a2c-41fb-98d1-110bcf49d38a  0.302132  0.110781  0.871149   \n",
      "3  dfe7b48e-21f0-4667-bb10-8039f7a50216  0.479809  0.270178  0.835371   \n",
      "4  d0c39593-5aa8-48c2-bfb0-1796128dfa7d  0.872977  0.458579  0.554084   \n",
      "\n",
      "     target  \n",
      "0  2.038140  \n",
      "1  1.109876  \n",
      "2  0.877694  \n",
      "3  1.478976  \n",
      "4  1.386923  \n"
     ]
    }
   ],
   "source": [
    "def generate_data(n):\n",
    "    \"\"\"\n",
    "    This function will generate n rows of sample data.\n",
    "    params:\n",
    "        n (Int) : The number of rows you want to generate\n",
    "    returns:\n",
    "        A pandas dataframe with n rows.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'uuid' : [str(uuid.uuid4()) for _ in range(n)],\n",
    "        'feature1' : [random.random() for _ in range(n)],\n",
    "        'feature2' : [random.random() for _ in range(n)],\n",
    "        'feature3' : [random.random() for _ in range(n)],\n",
    "        'target' : [sum([random.random(), random.random(), random.random()]) for _ in range(n)]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "  \n",
    "train_df = generate_data(2000)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "ft_cols = ['feature1', 'feature2', 'feature3']\n",
    "X = train_df[ft_cols].values\n",
    "Y = train_df['target'].values\n",
    "\n",
    "# X_train, X_test_, y_train, y_test = train_test_split(\n",
    "#     X, Y, test_size=0.3\n",
    "# )\n",
    "\n",
    "regressor = XGBRegressor().fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = generate_data(1500)\n",
    "test_df.drop(columns = ['target'], inplace = True)\n",
    "\n",
    "# generate predictions\n",
    "test_df['prediction'] = test_df[ft_cols].apply(lambda x : regressor.predict([x])[0], axis = 1)\n",
    "\n",
    "test_df = test_df.rename(columns = {\n",
    "    'feature1' : 'testfeature1',\n",
    "    'feature2' : 'testfeature2',\n",
    "    'feature3' : 'testfeature3'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.820826125417549\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def data_length_normalizer(gt_data, obs_data, bins = 100):\n",
    "    if len(gt_data) == len(obs_data):\n",
    "        return gt_data, obs_data \n",
    "\n",
    "    # scale bins accordingly to data size\n",
    "    if (len(gt_data) > 20*bins) and (len(obs_data) > 20*bins):\n",
    "        bins = 10*bins \n",
    "\n",
    "    # convert into frequency based distributions\n",
    "    gt_hist = plt.hist(gt_data, bins = bins)[0]\n",
    "    obs_hist = plt.hist(obs_data, bins = bins)[0]\n",
    "    plt.close()  # prevents plot from showing\n",
    "    return gt_hist, obs_hist \n",
    "\n",
    "def softmax(vec):\n",
    "    return(np.exp(vec)/np.exp(vec).sum())\n",
    "\n",
    "def calc_cross_entropy(p, q):\n",
    "    return entropy(p,q)\n",
    "    \n",
    "def calc_drift(gt_data, obs_data, gt_col, obs_col):\n",
    "    gt_data = gt_data[gt_col].values\n",
    "    obs_data = obs_data[obs_col].values\n",
    "\n",
    "    # makes sure the data is same size\n",
    "    gt_data, obs_data = data_length_normalizer(\n",
    "        gt_data = gt_data,\n",
    "        obs_data = obs_data\n",
    "    )\n",
    "    # convert to probabilities\n",
    "    gt_data = softmax(gt_data)\n",
    "    obs_data = softmax(obs_data)\n",
    "\n",
    "    # run drift scores\n",
    "    drift_score = calc_cross_entropy(gt_data, obs_data)\n",
    "    return drift_score\n",
    "    \n",
    "print(calc_drift(gt_data = train_df, obs_data = test_df, gt_col = 'feature1', obs_col = 'testfeature1'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
